整体思路


首先，用一个脚本（单进程）从各大网站（或者proxybroker）获取初步的代理。 (grab) valid=None
然后，用第二个脚本（多进程）进行测试，检测代理的有效性。 (check) valid=True or False
最后，有效的就放入数据库。 valid = True

问题1：
代理的寿命一般很短，存入数据库后，如何保证“每日新鲜”？
亚马逊爬虫有第二套自检机制，一旦抓取失败会延长下次使用该代理的时间。
如果失败率过高，该代理会被识别为无效，从而不会再被选中。
与此同时，永不停息地抓取野生的代理，检验入库。


##########

2018年2月27日更新

以上思路是理论。因为我目前的服务器的性能很差，不足以跑那么多进程。
因此暂时不跑check这一步。grab来的数据之间默认是valid。
如果失败率高了，自然会增加时间间隔，所以不用担心。